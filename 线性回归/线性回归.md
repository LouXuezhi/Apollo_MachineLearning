# 线性回归

## 回归

回归分析 根据数据 确定两种或两种以上变量间的相互依赖的定量关系

一元回归

多元回归

线性回归

非线性回归



# 线性回归

监督学习

$Y=aX+b$

$minmise\{\sum_{i=1}^m (y_i'-y_i)^2\}$

$minmise\{\frac{1}{2m}\sum_{i=1}^m (y_i'-y_i)^2\}$ -> 方便求导 -> 损失函数

m 为样本数 

y' 为输出结果

$minmise\{\frac{1}{2m}\sum_{i=1}^m (y_i'-y_i)^2\}=minmise\{\frac{1}{2m}\sum_{i=1}^m (ax+b-y_i)^2\}=g(a,b)$

**梯度下降法**

寻找极小值的一种方法。 通过向函数上当前点对应梯度（或近似梯度） 的反方向的规定 步长进行搜索，直到在极小值点收敛



$minmise\{\frac{1}{2m}\sum_{i=1}^m (y_i'-y_i)^2\}=minmise\{\frac{1}{2m}\sum_{i=1}^m (ax+b-y_i)^2\}=g(a,b)$


$$
\begin{Bmatrix}
temp_a=a-\alpha\frac{\partial}{\partial a}g(a,b)=a-\alpha\frac{1}{m}\sum_{i=1}^m(ax_i+b-y_i)x_i\\
temp_b=b-\alpha\frac{\partial}{\partial b}g(a,b)=b-\alpha\frac{1}{m}\sum_{i=1}^m(ax_i+b-y_i)\\
a=temp_a \\
b=temp_b
\end{Bmatrix}
$$


## 模型评估

### 均方误差 MSE

$$
MSE=\frac{1}{m}\sum_{i=1}^m (y_i'-y_i)^2
$$

### R方值

$$
R^2=1-\frac{\sum_{i=1}^m(y_i'-y_i)^2}{\sum_{i=1}^m(y_i-\overline{y_i})^2}=1-\frac{MSE}{方差}
$$



## 代码要点



## scikit-learn

机器学习算法

不包括 深度学习 和 强化学习

只支持Python 



MSE and K2

```python
from sklearn.metrics import mean_squared_error, r2_socre
MSE = mean_squared_error(y, y_predict)
R2 = r2_score(y, y_predict)
```



画图对比

```python
from matplotlib import pyplot as plt
plt.scatter(y, y_predict)
#画散点图 越集中于y=x 说明模型拟合得越好
```

